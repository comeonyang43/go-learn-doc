## 1. 介绍

随着哈希表中元素的逐渐增加，哈希的性能会逐渐恶化，所以我们需要更多的桶和更大的内存保证哈希的读写性能。

## 2. 怎么触发

在每次对哈希表**赋值**时，都会调用[`runtime.mapassign`](https://draveness.me/golang/tree/runtime.mapassign) 函数，该函数每次都会判断是否需要扩容，主要有两个函数：`overLoadFactory`和`tooManyOverflowBuckets`:

```go
// hash[k]=x表达式,会在编译期间转换成runtime.mapassign 函数的调用 
func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer {
	...
	if !h.growing() && (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) {
    // 扩容入口
		hashGrow(t, h)
		goto again
	}
	...
}
```

- `overLoadFactory`:  主要判断装载因子是否超过`6.5`
- `tooManyOverflowBuckets`: 用来判断是否使用了太多溢出桶；
- `h.growing()`: 用来判断是否已经处于扩容状态；

> 因为`Go` 语言哈希的扩容不是一个原子的过程，所以 [`runtime.mapassign`](https://draveness.me/golang/tree/runtime.mapassign) 还需要判断当前哈希是否已经处于扩容状态，避免二次扩容造成混乱。

## 3. 扩容方式

根据触发的条件不同扩容的方式分成两种：

- 第一种: 装载因子超过 `6.5`，则会进行双倍重建；

- 第二种: 当溢出桶的数量过多时，会进行等量重建；

### 3.1 等量扩容

当我们对`map`不断进行新增和删除时，桶中可能会出现很多断断续续的空位，这些空位会导致连接的`bmap`溢出桶很长，对应的扫描时间也会变长，查询性能就会下降。这种扩容实际上是一种整理，把后置位的数据整理到前面。

### 3.2 双倍重建

两倍重建是为了让`map`存储更多的数据,在双倍重建时，我们还需要解决旧桶中的数据要转移到某一个新桶中的问题。其中有一个非常重要的原则：如果数据的`hash&bucketMask`[当前新桶所在的位置]小于或等于旧桶的大小，则此数据必须转移到和旧桶位置完全对应的新桶中去，理由是当前`key`所在新桶的序号与旧桶是完全相同的。

## 4. 扩容流程

### 4.1 扩容核心函数

扩容需要处理的问题是，扩容后，`map`中原本的数据重新放到扩容后的`map`中，即数据迁移问题，`golang`中`map`扩容时核心函数有如下几个

- `hashGrow`：决定扩容方式，负责初始化新的桶，以及设置扩容后的`map`的各个字段

- `growWork`：每调用一次`growWork`函数，都至多会迁移两个桶的数据

- `evacuate`：真正负责迁移数据的函数，会负责迁移指定桶中的数据

- `advanceEvacuationMark`：收尾工作，增加`nevacuate`，如果所有的`oldbuckets`都迁移完成了，会摘除`oldbuckets`

### 4.2 hashGrow

重建时需要调用`hashGrow`函数，<font color=blue>如果负载因子超载，则会进行双倍重建。当溢出桶的数量过多时，会进行等量重建。</font>新桶会存储到`buckets`字段，旧桶会存储到`oldbuckets`字段。`map`中`extra`字段的溢出桶也进行同样的转移。

```go
func hashGrow(t *maptype, h *hmap) {
	bigger := uint8(1)
	if !overLoadFactor(h.count+1, h.B) {
		bigger = 0
		h.flags |= sameSizeGrow
	}
  // 旧数据存到旧桶
	oldbuckets := h.buckets
  // 创建一组新桶和溢出桶
	newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil)

	h.B += bigger
	h.flags = flags
  // 旧数据存到旧桶上
	h.oldbuckets = oldbuckets
	h.buckets = newbuckets
	h.nevacuate = 0
	h.noverflow = 0
  // 原有的溢出桶，存到旧溢出桶
	h.extra.oldoverflow = h.extra.overflow
	h.extra.overflow = nil
	h.extra.nextOverflow = nextOverflow
}
```

> <font color=red>@注意：这里并没有实际执行将旧桶中的数据转移到新桶的过程。数据转移遵循写时复制（copy on write）的规则，只有在真正赋值时，才会选择是否需要进行数据转移，其核心逻辑位于growWork和evacuate函数中。</font>

![扩容后的map的各个字段](https://img.draveness.me/2020-10-18-16030322432573/hashmap-hashgrow.png)

### 4.3 growWork

`growWork`函数并不会真正进行数据迁移，它会调用`evacuate`函数来完成迁移工作，`growWork`函数每次会迁移至多两个桶的数据，一个是目前需要使用的桶，一个是`h.nevacuate`桶（这里很重要，在后面判断是否迁移过程中有很大的作用），`h.nevacuate`记录的是目前至少已经迁移的桶的个数。

```go
func growWork(t *maptype, h *hmap, bucket uintptr) {
	// make sure we evacuate the oldbucket corresponding
	// to the bucket we're about to use
	evacuate(t, h, bucket&h.oldbucketmask())

	// evacuate one more oldbucket to make progress on growing
	if h.growing() {
		evacuate(t, h, h.nevacuate)
	}
}
```

### 4.4 evacuate









https://juejin.cn/post/7102005935081521160



